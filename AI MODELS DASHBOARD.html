<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Combined AI Model Dashboard</title>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&display=swap');

        :root {
            /* Unified Light Theme */
            --background-color: #F4F7F6;
            --header-bg: #FFFFFF;
            --table-bg: #FFFFFF;
            --text-dark: #222222;
            --text-light: #555555;
            --shadow: rgba(0, 0, 0, 0.08);
            --border-color: #E0E0E0;
            --active-color: #005A9C; /* A professional blue */
            --header-accent: #333;
            --row-highlight: #F9F9F9;
        }

        body {
            font-family: 'Roboto', sans-serif;
            margin: 0;
            padding: 0;
            background-color: var(--background-color);
            color: var(--text-dark);
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            padding-bottom: 40px;
        }

        .dashboard-container {
            width: 90%;
            max-width: 1400px;
            margin-top: 30px;
        }

        header {
            width: 100%;
            background-color: var(--header-bg);
            color: var(--header-accent);
            padding: 20px 0;
            text-align: center;
            box-shadow: 0 2px 4px var(--shadow);
            margin-bottom: 30px;
            border-bottom: 3px solid var(--active-color);
        }

        h1 {
            margin: 0;
            font-weight: 700;
        }
        
        h2 {
            font-size: 1.8em;
            color: var(--active-color);
            border-bottom: 2px solid var(--border-color);
            padding-bottom: 10px;
            margin-top: 40px;
        }

        .search-bar {
            width: 100%;
            display: flex;
            justify-content: center;
            margin-bottom: 20px;
        }

        .search-bar input {
            width: 80%;
            max-width: 600px;
            padding: 12px 20px;
            border: 1px solid var(--border-color);
            border-radius: 25px;
            font-size: 1.1em;
            outline: none;
            transition: all 0.3s ease;
            background-color: #FFFFFF;
        }
        
        .search-bar input:focus {
            border-color: var(--active-color);
            box-shadow: 0 0 8px 0 rgba(0, 90, 156, 0.2);
        }

        .table-container {
            overflow-x: auto;
            background-color: var(--table-bg);
            border-radius: 8px;
            box-shadow: 0 4px 12px 0 var(--shadow);
        }

        table {
            width: 100%;
            border-collapse: collapse;
        }

        th, td {
            padding: 14px 18px;
            text-align: left;
            border-bottom: 1px solid var(--border-color);
            white-space: normal;
            font-size: 0.95em;
            color: var(--text-light);
        }

        th {
            background-color: #F8F8F8;
            font-weight: 700;
            color: var(--text-dark);
            font-size: 1em;
        }

        tbody tr:nth-of-type(even) {
            background-color: var(--row-highlight);
        }
        
        tbody tr:hover {
            background-color: #EAF6FF; /* Light blue hover */
        }
        
        td:first-child {
            font-weight: bold;
            color: var(--active-color);
            white-space: nowrap;
        }
        
        td em {
            font-style: italic;
            color: #444;
        }

        .juice-badge {
            display: inline-block;
            margin-left: 8px;
            font-size: 0.85em;
            font-weight: 400;
            vertical-align: middle;
            color: var(--text-light);
            white-space: nowrap;
        }
    </style>
</head>
<body>
    <header>
        <h1>Combined AI Model Dashboard</h1>
    </header>

    <div class="dashboard-container">
        <div class="search-bar">
            <input type="text" id="searchInput" placeholder="Search all models, uses, or examples...">
        </div>

        <!-- Perplexity Section (Existing) -->
        <section id="perplexity-section">
            <h2>Perplexity AI Models</h2>
            <div class="table-container" id="perplexityTableContainer">
                <!-- Content generated by JS -->
            </div>
        </section>

        <!-- ChatGPT Section (Existing) -->
        <section id="chatgpt-section">
            <h2>ChatGPT Models</h2>
            <div class="table-container" id="chatgptTableContainer">
                <!-- Content generated by JS -->
            </div>
        </section>

        <!-- NEW Claude AI Section -->
        <section id="claude-section">
            <h2>Claude AI Models</h2>
            <div class="table-container" id="claudeTableContainer">
                <!-- Content generated by JS -->
            </div>
        </section>

    </div>

    <script>
        // --- Data ---
        const perplexityModels = [
            { modelName: "Sonar", priorityUse: "Fast, grounded, web search", recommendedFor: "Real-time factual Q&A, news, source gathering, rapid synthesis", promptExample: "List key findings from the latest IPCC report on climate change and cite each.", juice: 16 },
            { modelName: "Claude Sonnet 4.5", priorityUse: "Nuanced language, ethical/legal", recommendedFor: "Legal text review, professional email drafting, complex policy analysis", promptExample: "Draft a privacy statement for a fintech app, ensuring GDPR compliance.", juice: 64 },
            { modelName: "Claude Sonnet 4.5 Thinking", priorityUse: "In-depth reasoning, ethics", recommendedFor: "AI ethics, philosophical debates, stepwise risk analysis", promptExample: "Assess the ethical implications of deploying facial recognition in schools.", juice: 128 },
            { modelName: "Claude Opus 4.1 Thinking", priorityUse: "Premium, detailed, slow max", recommendedFor: "Scholarly writing, research rationales, logic puzzles", promptExample: "Step-by-step, write a peer review of this AI ethics manuscript.", juice: 200 },
            { modelName: "Gemini 2.5 Pro", priorityUse: "Advanced multimodal, Google tech", recommendedFor: "Data visualization, code, spreadsheets, Google ecosystem integration", promptExample: "Write a script to convert these PDFs to Excel and summarize key data points.", juice: 64 },
            { modelName: "GPT-5", priorityUse: "Deep reasoning, creative tasks", recommendedFor: "Complex Q&A, ideation, technical writing, code and logic-heavy queries", promptExample: "Break down how quantum computers differ from classical computers at the architectural and logical level.", juice: 64 },
            { modelName: "GPT-5 Thinking", priorityUse: "Extended reasoning, step-by-step", recommendedFor: "Technical walkthroughs, mathematical proofs, guided multi-step analysis", promptExample: "Solve this multi-stage econometrics problem, showing all your reasoning.", juice: 128 },
            { modelName: "o3-pro (OpenAI)", priorityUse: "Max speed+logic, bulk tasks", recommendedFor: "Batch Q&A, cost-efficient logic tasks, long-form batch synthesis", promptExample: "Summarize and contrast five recent papers on reinforcement learning trends.", juice: 64 },
            { modelName: "Grok 4", priorityUse: "Up-to-date trends, wit, creative", recommendedFor: "Hot topic analysis, social commentary, brainstorming, exploring niche ideas", promptExample: "Generate a satirical summary of recent AI policy news in the US and EU.", juice: 16 }
        ];

        const chatGPTModels = [
            { modelName: "GPT-5 (Auto)", priorityUse: "Default mode, auto-switching", recommendedFor: "General purpose use. The model decides whether to use a fast response or deeper reasoning based on your prompt's complexity.", promptExample: "Explain the main causes of the Roman Republic's collapse and what modern parallels, if any, exist.", juice: "Varies" },
            { modelName: "GPT-5 (Instant)", priorityUse: "Answers right away", recommendedFor: "Quick facts, simple Q&A, brainstorming, and routine tasks like drafting short emails or summaries where speed is preferred.", promptExample: "What are the top 5 largest cities in the world by population, and what is the official language of each?", juice: 5 },
            { modelName: "GPT-5 (Thinking)", priorityUse: "Thinks longer for better answers", recommendedFor: "Deeper, step-by-step reasoning for complex tasks. Use for multi-step math problems, advanced coding and debugging, or strategic planning.", promptExample: "Think step-by-step. Propose a 4-week plan to reduce my household spending while sticking to a healthy meal plan for a family of four.", juice: 18 },
            { modelName: "GPT-5 (Pro)", priorityUse: "Research-grade intelligence (Pro Plan)", recommendedFor: "Mission-critical, high-stakes tasks where maximum accuracy is required. Uses parallel reasoning to find the best answer. Ideal for financial modeling, in-depth legal review, or biopharma research.", promptExample: "Perform a detailed financial risk assessment for a US-based tech startup expanding into the EU market, focusing on data privacy compliance and supply chain vulnerabilities.", juice: 200 },
            { modelName: "GPT-4o", priorityUse: "Multimodal speed & interaction", recommendedFor: "Natively integrates text, audio, and image understanding. Best for real-time voice conversations, live translation, and analyzing uploaded images or screenshots.", promptExample: "Here is a screenshot of my website's homepage. Give me five suggestions to improve the user experience and visual layout.", juice: "N/A" },
            { modelName: "GPT-4.1", priorityUse: "Coding & instruction specialist", recommendedFor: "Precise, long-context instruction following (up to 1M tokens). Ideal for software development, debugging large codebases, or analyzing dense legal/financial documents.", promptExample: "Review this entire 200-page codebase, identify the source of the memory leak in the 'user_session' module, and suggest a fix.", juice: "N/A" },
            { modelName: "o3", priorityUse: "Advanced reasoning model (Pro Plan)", recommendedFor: "A powerful reasoning-focused model. Best for rigorous logical or mathematical problems, scientific reasoning, and developing business strategies.", promptExample: "Develop a comprehensive risk analysis for a mid-sized e-commerce company planning to expand its market into Southeast Asia.", juice: 64 },
            { modelName: "o4-mini", priorityUse: "Fast, cost-efficient reasoning (Pro Plan)", recommendedFor: "A smaller, faster model optimized for low-latency logic, math, and coding tasks where cost-efficiency is important.", promptExample: "Explain the concept of 'technical debt' in layman's terms and draft a simple SQL query to find all active users.", juice: 5 }
        ];

        // --- NEW Claude AI Model Data ---
        const claudeModels = [
            { 
                modelName: "Opus 4.1", 
                priorityUse: "Flagship / Frontier Reasoning - Deep research, long-form writing, complex analysis", 
                recommendedFor: "Most powerful model with superior precision in complex agentic tasks; supports up to 200K token context; ideal for high-accuracy coding and enterprise applications. (Speed: Slowest / Cost: Highest)", 
                promptExample: "Conduct deep research and complex analysis on [multi-step logic workflow].", 
                juice: 95 
            },
            { 
                modelName: "Sonnet 4.5", 
                priorityUse: "Balanced / Everyday Frontier - Coding, agents, complex Q&A", 
                recommendedFor: "Best coding model; excels at agent workflows and computer use; supports 1M token context; strong reasoning with balanced speed. (Speed: Mid / Cost: Mid-high)", 
                promptExample: "Analyze this codebase and create an agent workflow for [enterprise app feature].", 
                juice: 92 
            },
            { 
                modelName: "Haiku 4.5", 
                priorityUse: "Lightweight / Fastest - Real-time assistants, customer chat", 
                recommendedFor: "Smallest and fastest model; near-frontier performance; optimized for efficiency and real-time responsiveness; 3x faster throughput than Sonnet. (Speed: Fastest / Cost: Lowest)", 
                promptExample: "Act as a real-time assistant to answer [customer chat question].", 
                juice: 85 
            },
            { 
                modelName: "Opus 4.0", 
                priorityUse: "Previous Flagship (2024) - High-accuracy writing, deep reasoning", 
                recommendedFor: "Superseded by Opus 4.1; improved alignment and memory; still used in some stable enterprise integrations. (Speed: Slow / Cost: High)", 
                promptExample: "Write a high-accuracy, deeply reasoned article on [scholarly topic].", 
                juice: 88 
            },
            { 
                modelName: "Sonnet 4.0", 
                priorityUse: "Prior Balanced Model - Professional writing, legal drafting", 
                recommendedFor: "Introduced major alignment improvements and context expansion vs Claude 3 series; still in use for reliability. (Speed: Medium / Cost: Medium)", 
                promptExample: "Draft this professional legal document about [technical task].", 
                juice: 82 
            },
            { 
                modelName: "Sonnet 3.7", 
                priorityUse: "Transitional / Legacy - Everyday Q&A, email drafting", 
                recommendedFor: "Late-Claude 3 model with good language quality; limited to 200K context; inferior reasoning depth. (Speed: Fast / Cost: Low)", 
                promptExample: "Draft an email for [general chat topic].", 
                juice: 75 
            },
            { 
                modelName: "Opus 3", 
                priorityUse: "Legacy Flagship (2023) - Extended reasoning and research", 
                recommendedFor: "First to introduce large-context capability; inferior to 4-series in tool use, alignment, and safety. (Speed: Slow / Cost: High (legacy))", 
                promptExample: "Perform extended reasoning and research on [complex topic].", 
                juice: 70 
            },
            { 
                modelName: "Haiku 3.5", 
                priorityUse: "Legacy Fast Model (2023) - Quick customer support, real-time reply", 
                recommendedFor: "Small model optimized for speed and low cost; superseded by Haiku 4.5 with better coding and safety. (Speed: Fast / Cost: Lowest (legacy))", 
                promptExample: "Provide a quick, real-time reply for [customer support issue].", 
                juice: 68 
            }
        ];

        // --- DOM Elements ---
        const searchInput = document.getElementById('searchInput');
        const perplexityTableContainer = document.getElementById('perplexityTableContainer');
        const chatgptTableContainer = document.getElementById('chatgptTableContainer');
        const claudeTableContainer = document.getElementById('claudeTableContainer'); // New container
        
        // --- Event Listeners ---
        searchInput.addEventListener('keyup', updateAllTables);

        // --- Functions ---
        function updateAllTables() {
            const filterText = searchInput.value.toLowerCase();
            renderPerplexityTable(filterText);
            renderChatGPTTable(filterText);
            renderClaudeTable(filterText); // New function call
        }

        function filterModels(models, filterText = '') {
            if (!filterText) return models;
            return models.filter(model => {
                const searchString = `${model.modelName} ${model.priorityUse} ${model.recommendedFor} ${model.promptExample} ${model.juice}`.toLowerCase();
                return searchString.includes(filterText);
            });
        }

        // Generic table renderer
        function renderTable(container, models, filterText) {
            const filteredModels = filterModels(models, filterText);
            let tableHTML = `
                <table>
                    <thead>
                        <tr>
                            <th>Model Name</th>
                            <th>Priority Use/Mode</th>
                            <th>Recommended For</th>
                            <th>Example Prompt</th>
                        </tr>
                    </thead>
                    <tbody>
            `;
            
            filteredModels.forEach(model => {
                tableHTML += `
                    <tr>
                        <td>
                            ${model.modelName}
                            <span class="juice-badge">💧 J=${model.juice}</span>
                        </td>
                        <td>${model.priorityUse}</td>
                        <td>${D(model.recommendedFor)}</td>
                        <td><em>"${D(model.promptExample)}"</em></td>
                    </tr>
                `;
            });

            tableHTML += '</tbody></table>';
            container.innerHTML = tableHTML;
        }

        // --- Specific Render Functions ---
        function renderPerplexityTable(filterText = '') {
            renderTable(perplexityTableContainer, perplexityModels, filterText);
        }

        function renderChatGPTTable(filterText = '') {
            renderTable(chatgptTableContainer, chatGPTModels, filterText);
        }

        // New render function for Claude
        function renderClaudeTable(filterText = '') {
            renderTable(claudeTableContainer, claudeModels, filterText);
        }
        
        // Helper function to decode HTML entities (if any)
        function D(text) {
            const el = document.createElement('textarea');
            el.innerHTML = text;
            return el.value;
        }

        // --- Initial Load ---
        updateAllTables(); // Initial render of all tables
    </script>
</body>
</html>
